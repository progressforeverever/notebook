{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[58],{387:function(s,t,a){\"use strict\";a.r(t);var n=a(4),e=Object(n.a)({},(function(){var s=this,t=s._self._c;return t(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":s.$parent.slotKey}},[t(\"blockquote\",[t(\"p\",[s._v(\"感谢 \"),t(\"a\",{attrs:{href:\"https://github.com/changfubai\",target:\"_blank\",rel:\"noopener noreferrer\"}},[s._v(\"changfubai\"),t(\"OutboundLink\")],1),s._v(\" 对本文的改进做出的贡献！\")])]),s._v(\" \"),t(\"h2\",{attrs:{id:\"hashmap-简介\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#hashmap-简介\"}},[s._v(\"#\")]),s._v(\" HashMap 简介\")]),s._v(\" \"),t(\"p\",[s._v(\"HashMap 主要用来存放键值对，它基于哈希表的 Map 接口实现，是常用的 Java 集合之一，\"),t(\"strong\",[s._v(\"是非线程安全的。\")])]),s._v(\" \"),t(\"p\",[t(\"strong\",[t(\"code\",[s._v(\"HashMap\")]),s._v(\" 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个\")])]),s._v(\" \"),t(\"p\",[t(\"strong\",[s._v(\"JDK1.8 之前 HashMap 由 数组+链表 组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。\")]),s._v(\" JDK1.8 以后的 \"),t(\"code\",[s._v(\"HashMap\")]),s._v(\" 在解决哈希冲突时有了较大的变化，\"),t(\"strong\",[s._v(\"当链表长度大于等于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。\")])]),s._v(\" \"),t(\"p\",[t(\"strong\",[t(\"code\",[s._v(\"HashMap\")]),s._v(\" 默认的初始化大小为 16。之后每次扩充，容量变为原来的 2 倍。并且， \"),t(\"code\",[s._v(\"HashMap\")]),s._v(\" 总是使用 2 的幂作为哈希表的大小。\")])]),s._v(\" \"),t(\"h2\",{attrs:{id:\"底层数据结构分析\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#底层数据结构分析\"}},[s._v(\"#\")]),s._v(\" 底层数据结构分析\")]),s._v(\" \"),t(\"h3\",{attrs:{id:\"jdk1-8-之前\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#jdk1-8-之前\"}},[s._v(\"#\")]),s._v(\" JDK1.8 之前\")]),s._v(\" \"),t(\"p\",[s._v(\"JDK1.8 之前 HashMap 底层是 \"),t(\"strong\",[s._v(\"数组和链表\")]),s._v(\" 结合在一起使用也就是 \"),t(\"strong\",[s._v(\"链表散列\")]),s._v(\"。\")]),s._v(\" \"),t(\"p\",[s._v(\"HashMap 通过 key 的 hashCode 经过扰动函数处理过后得到 hash 值，然后通过 \"),t(\"code\",[s._v(\"(n - 1) & hash\")]),s._v(\" 判断当前元素存放的位置（这里的 n 指的是数组的长度），\"),t(\"strong\",[s._v(\"如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。\")])]),s._v(\" \"),t(\"p\",[t(\"strong\",[s._v(\"所谓扰动函数指的就是 HashMap 的 hash 方法。使用 hash 方法也就是扰动函数是为了防止一些实现比较差的 hashCode() 方法 换句话说使用扰动函数之后可以减少碰撞。\")])]),s._v(\" \"),t(\"p\",[t(\"strong\",[s._v(\"JDK 1.8 HashMap 的 hash 方法源码:\")])]),s._v(\" \"),t(\"p\",[s._v(\"JDK 1.8 的 hash 方法 相比于 JDK 1.7 hash 方法更加简化，但是原理不变。\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-java line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[t(\"code\",[s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"static\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"hash\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Object\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n      \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" h\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n      \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// key.hashCode()：返回散列值也就是hashcode\")]),s._v(\"\\n      \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// ^：按位异或\")]),s._v(\"\\n      \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// >>>:无符号右移，忽略符号位，空位都以0补齐\")]),s._v(\"\\n      \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"key \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"?\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\":\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"h \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"hashCode\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"^\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"h \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\">>>\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"16\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n  \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\")])]),t(\"p\",[s._v(\"对比一下 JDK1.7 的 HashMap 的 hash 方法源码.\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-java line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"static\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"hash\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" h\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// This function ensures that hashCodes that differ only by\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// constant multiples at each bit position have a bounded\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// number of collisions (approximately 8 at default load factor).\")]),s._v(\"\\n\\n    h \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"^=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"h \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\">>>\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"20\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"^\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"h \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\">>>\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"12\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" h \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"^\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"h \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\">>>\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"7\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"^\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"h \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\">>>\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"4\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\")])]),t(\"p\",[s._v(\"相比于 JDK1.8 的 hash 方法 ，JDK 1.7 的 hash 方法的性能会稍差一点点，因为毕竟扰动了 4 次。\")]),s._v(\" \"),t(\"p\",[s._v(\"所谓 \"),t(\"strong\",[s._v(\"“拉链法”\")]),s._v(\" 就是：将链表和数组相结合。也就是说创建一个链表数组，数组中每一格就是一个链表。若遇到哈希冲突，则将冲突的值加到链表中即可。\")]),s._v(\" \"),t(\"p\",[t(\"img\",{attrs:{src:\"https://czynotebook.oss-cn-beijing.aliyuncs.com/notebook/jdk1.7_hashmap.png\",alt:\"jdk1.8 之前的内部结构-HashMap\"}})]),s._v(\" \"),t(\"h3\",{attrs:{id:\"jdk1-8-之后\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#jdk1-8-之后\"}},[s._v(\"#\")]),s._v(\" JDK1.8 之后\")]),s._v(\" \"),t(\"p\",[s._v(\"相比于之前的版本，JDK1.8 以后在解决哈希冲突时有了较大的变化。\")]),s._v(\" \"),t(\"p\",[t(\"strong\",[s._v(\"当链表长度大于阈值（默认为 8）时，会首先调用 \"),t(\"code\",[s._v(\"treeifyBin()\")]),s._v(\"方法。这个方法会根据 HashMap 数组来决定是否转换为红黑树\")]),s._v(\"。**只有当数组长度大于或者等于 64 的情况下，才会执行转换红黑树操作，以减少搜索时间。否则，就是只是执行 \"),t(\"code\",[s._v(\"resize()\")]),s._v(\" 方法对数组扩容。**相关源码这里就不贴了，重点关注 \"),t(\"code\",[s._v(\"treeifyBin()\")]),s._v(\"方法即可！\")]),s._v(\" \"),t(\"p\",[t(\"img\",{attrs:{src:\"https://czynotebook.oss-cn-beijing.aliyuncs.com/notebook/jdk1.8_hashmap.png\",alt:\"jdk1.8之后的内部结构-HashMap\"}})]),s._v(\" \"),t(\"p\",[t(\"strong\",[s._v(\"类的属性：\")])]),s._v(\" \"),t(\"div\",{staticClass:\"language-java line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"public\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"class\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"HashMap\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"extends\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"AbstractMap\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"implements\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Map\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Cloneable\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Serializable\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 序列号\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"private\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"static\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"long\")]),s._v(\" serialVersionUID \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"362498820763181265L\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 默认的初始容量是16\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"static\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"DEFAULT_INITIAL_CAPACITY\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"<<\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"4\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 最大容量\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"static\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"MAXIMUM_CAPACITY\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"<<\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"30\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 默认的负载因子\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"static\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"float\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"DEFAULT_LOAD_FACTOR\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0.75f\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 当桶(bucket)上的结点数大于等于这个值时会转成红黑树\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"static\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"TREEIFY_THRESHOLD\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"8\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 当桶(bucket)上的结点数小于等于这个值时树转链表\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"static\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"UNTREEIFY_THRESHOLD\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"6\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 桶中结构转化为红黑树对应的table的最小容量\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"static\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"MIN_TREEIFY_CAPACITY\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"64\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 存储元素的数组，总是2的幂次倍\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"transient\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),s._v(\"k\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\"v\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\" table\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 存放具体元素的集\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"transient\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Set\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),s._v(\"map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"entry\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),s._v(\"k\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\"v\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" entrySet\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 存放元素的个数，注意这个不等于数组的长度。\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"transient\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" size\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 每次扩容和更改map结构的计数器\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"transient\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" modCount\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 阈值(容量*负载因子) 当实际大小超过阈值时，会进行扩容\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" threshold\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 负载因子\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"float\")]),s._v(\" loadFactor\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"15\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"16\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"17\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"18\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"19\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"20\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"21\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"22\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"23\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"24\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"25\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"26\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"27\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"28\")]),t(\"br\")])]),t(\"ul\",[t(\"li\",[t(\"p\",[t(\"strong\",[s._v(\"loadFactor 负载因子\")])]),s._v(\" \"),t(\"p\",[t(\"strong\",[s._v(\"loadFactor 负载因子是控制数组存放数据的疏密程度，loadFactor 越趋近于 1，那么 数组中存放的数据(entry)也就越多，也就越密，也就是会让链表的长度增加，loadFactor 越小，也就是趋近于 0，数组中存放的数据(entry)也就越少，也就越稀疏。\")])]),s._v(\" \"),t(\"p\",[t(\"strong\",[s._v(\"loadFactor 太大导致查找元素效率低，太小导致数组的利用率低，存放的数据会很分散。loadFactor 的默认值为 0.75f 是官方给出的一个比较好的临界值\")]),s._v(\"。\")]),s._v(\" \"),t(\"p\",[t(\"strong\",[s._v(\"给定的默认容量为 16，负载因子为 0.75\")]),s._v(\"。Map 在使用过程中不断的往里面存放数据，\"),t(\"strong\",[s._v(\"当数量超过了 16 * 0.75 = 12 就需要将当前 16 的容量进行扩容，而扩容这个过程涉及到 rehash、复制数据等操作，所以非常消耗性能。\")])])]),s._v(\" \"),t(\"li\",[t(\"p\",[t(\"strong\",[s._v(\"threshold\")])]),s._v(\" \"),t(\"p\",[t(\"strong\",[s._v(\"threshold = capacity * loadFactor\")]),s._v(\"，\"),t(\"strong\",[s._v(\"当 Size>threshold\")]),s._v(\"的时候，那么就要考虑对数组的扩增了，也就是说，这个的意思就是 \"),t(\"strong\",[s._v(\"衡量数组是否需要扩增的一个标准\")]),s._v(\"。\")])])]),s._v(\" \"),t(\"p\",[t(\"strong\",[s._v(\"Node 节点类源码:\")])]),s._v(\" \"),t(\"div\",{staticClass:\"language-java line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 继承自 Map.Entry<K,V>\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"static\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"class\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"implements\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"Entry\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n       \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" hash\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 哈希值，存放元素到hashmap中时用来与其他元素hash值比较\")]),s._v(\"\\n       \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//键\")]),s._v(\"\\n       \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//值\")]),s._v(\"\\n       \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 指向下一个节点\")]),s._v(\"\\n       \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" next\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n       \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" hash\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" next\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"this\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"hash \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" hash\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"this\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"key \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"this\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"value \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"this\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"next \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" next\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"public\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"getKey\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"public\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"getValue\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"      \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"public\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"String\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"toString\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" key \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"+\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"=\"')]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"+\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 重写hashCode()方法\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"public\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"hashCode\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Objects\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"hashCode\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"^\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Objects\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"hashCode\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"public\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"setValue\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),s._v(\" newValue\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),s._v(\" oldValue \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            value \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" newValue\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" oldValue\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 重写 equals() 方法\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"public\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"boolean\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"equals\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Object\")]),s._v(\" o\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"o \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"this\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"true\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"o \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"instanceof\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"Entry\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"Entry\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"?\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"?\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" e \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"Entry\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"?\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"?\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"o\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Objects\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"equals\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"getKey\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&&\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Objects\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"equals\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"getValue\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"true\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"false\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"15\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"16\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"17\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"18\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"19\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"20\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"21\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"22\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"23\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"24\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"25\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"26\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"27\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"28\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"29\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"30\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"31\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"32\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"33\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"34\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"35\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"36\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"37\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"38\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"39\")]),t(\"br\")])]),t(\"p\",[t(\"strong\",[s._v(\"树节点类源码:\")])]),s._v(\" \"),t(\"div\",{staticClass:\"language-java line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"static\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"class\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"TreeNode\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"extends\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"LinkedHashMap\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"Entry\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"TreeNode\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" parent\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"  \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 父\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"TreeNode\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" left\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 左\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"TreeNode\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" right\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"   \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 右\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"TreeNode\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" prev\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// needed to unlink next upon deletion\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"boolean\")]),s._v(\" red\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"           \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 判断颜色\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"TreeNode\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" hash\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),s._v(\" val\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" next\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"super\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"hash\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" val\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" next\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 返回根节点\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"TreeNode\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"root\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"for\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"TreeNode\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" r \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"this\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" p\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"p \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" r\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"parent\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" r\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                r \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" p\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n       \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"15\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"16\")]),t(\"br\")])]),t(\"h2\",{attrs:{id:\"hashmap-源码分析\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#hashmap-源码分析\"}},[s._v(\"#\")]),s._v(\" HashMap 源码分析\")]),s._v(\" \"),t(\"h3\",{attrs:{id:\"构造方法\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#构造方法\"}},[s._v(\"#\")]),s._v(\" 构造方法\")]),s._v(\" \"),t(\"p\",[s._v(\"HashMap 中有四个构造方法，它们分别如下：\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-java line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[t(\"code\",[s._v(\"    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 默认构造函数。\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"public\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"HashMap\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"this\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"loadFactor \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"DEFAULT_LOAD_FACTOR\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// all   other fields defaulted\")]),s._v(\"\\n     \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\\n     \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 包含另一个“Map”的构造函数\")]),s._v(\"\\n     \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"public\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"HashMap\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Map\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"?\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"extends\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"?\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"extends\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" m\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n         \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"this\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"loadFactor \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"DEFAULT_LOAD_FACTOR\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n         \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"putMapEntries\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"m\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"false\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//下面会分析到这个方法\")]),s._v(\"\\n     \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\\n     \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 指定“容量大小”的构造函数\")]),s._v(\"\\n     \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"public\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"HashMap\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" initialCapacity\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n         \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"this\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"initialCapacity\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"DEFAULT_LOAD_FACTOR\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n     \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\\n     \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 指定“容量大小”和“负载因子”的构造函数\")]),s._v(\"\\n     \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"public\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"HashMap\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" initialCapacity\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"float\")]),s._v(\" loadFactor\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n         \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"initialCapacity \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"<\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n             \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"throw\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"new\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"IllegalArgumentException\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"Illegal initial capacity: \"')]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"+\")]),s._v(\" initialCapacity\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n         \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"initialCapacity \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\">\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"MAXIMUM_CAPACITY\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n             initialCapacity \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"MAXIMUM_CAPACITY\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n         \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"loadFactor \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"<=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"||\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Float\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"isNaN\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"loadFactor\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n             \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"throw\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"new\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"IllegalArgumentException\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"Illegal load factor: \"')]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"+\")]),s._v(\" loadFactor\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n         \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"this\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"loadFactor \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" loadFactor\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n         \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 初始容量暂时存放到 threshold ，在resize中再赋值给 newCap 进行table初始化\")]),s._v(\"\\n         \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"this\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"threshold \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"tableSizeFor\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"initialCapacity\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n     \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"15\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"16\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"17\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"18\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"19\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"20\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"21\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"22\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"23\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"24\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"25\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"26\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"27\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"28\")]),t(\"br\")])]),t(\"blockquote\",[t(\"p\",[s._v(\"值得注意的是上述四个构造方法中，\"),t(\"strong\",[s._v(\"都初始化了负载因子 loadFactor\")]),s._v(\"，由于 HashMap 中没有 capacity 这样的字段，\"),t(\"strong\",[s._v(\"即使指定了初始化容量 initialCapacity ，也只是通过 tableSizeFor 将其扩容到与 initialCapacity 最接近的 2 的幂次方大小 ，所以HashMap的大小一直都得是二的幂次方\")]),s._v(\"  ，然后\"),t(\"strong\",[s._v(\"暂时赋值给 threshold\")]),s._v(\" ，后续通过 resize 方法将 threshold 赋值给 newCap 进行 table 的初始化。\")])]),s._v(\" \"),t(\"p\",[t(\"strong\",[s._v(\"putMapEntries 方法：\")])]),s._v(\" \"),t(\"div\",{staticClass:\"language-java line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"void\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"putMapEntries\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Map\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"?\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"extends\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"?\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"extends\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" m\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"boolean\")]),s._v(\" evict\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" s \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" m\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"size\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"s \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\">\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 判断table是否已经初始化\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"table \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// pre-size\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"/*\\n             * 未初始化，s为m的实际元素个数，ft=s/loadFactor => s=ft*loadFactor, 跟我们前面提到的\\n             * 阈值=容量*负载因子 是不是很像，是的，ft指的是要添加s个元素所需的最小的容量\\n             */\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"float\")]),s._v(\" ft \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"float\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"s \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"/\")]),s._v(\" loadFactor\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"+\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1.0F\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" t \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"ft \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"<\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"float\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"MAXIMUM_CAPACITY\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"?\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"ft \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\":\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"MAXIMUM_CAPACITY\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"/*\\n             * 根据构造函数可知，table未初始化，threshold实际上是存放的初始化容量，如果添加s个元素所\\n             * 需的最小容量大于初始化容量，则将最小容量扩容为最接近的2的幂次方大小作为初始化。\\n             * 注意这里不是初始化阈值\\n             */\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"t \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\">\")]),s._v(\" threshold\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n                threshold \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"tableSizeFor\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"t\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 已初始化，并且m元素个数大于阈值，进行扩容处理\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"else\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"s \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\">\")]),s._v(\" threshold\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"resize\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 将m中的所有元素添加至HashMap中，如果table未初始化，putVal中会调用resize初始化或扩容\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"for\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"Entry\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"?\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"extends\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"?\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"extends\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" e \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\":\")]),s._v(\" m\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"entrySet\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),s._v(\" key \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"getKey\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),s._v(\" value \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"getValue\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"putVal\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"hash\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"false\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" evict\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"15\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"16\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"17\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"18\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"19\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"20\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"21\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"22\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"23\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"24\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"25\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"26\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"27\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"28\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"29\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"30\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"31\")]),t(\"br\")])]),t(\"h3\",{attrs:{id:\"put-方法\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#put-方法\"}},[s._v(\"#\")]),s._v(\" put 方法\")]),s._v(\" \"),t(\"p\",[s._v(\"HashMap 只提供了 put 用于添加元素，putVal 方法只是给 put 方法调用的一个方法，并没有提供给用户使用。\")]),s._v(\" \"),t(\"p\",[t(\"strong\",[s._v(\"对 putVal 方法添加元素的分析如下：\")])]),s._v(\" \"),t(\"ol\",[t(\"li\",[s._v(\"如果定位到的数组位置没有元素 就直接插入。\")]),s._v(\" \"),t(\"li\",[s._v(\"如果定位到的数组位置有元素就和要插入的 key 比较，如果 key 相同就直接覆盖，如果 key 不相同，就判断 p 是否是一个树节点，如果是就调用\"),t(\"code\",[s._v(\"e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value)\")]),s._v(\"将元素添加进入。如果不是就遍历链表插入(插入的是链表尾部)。\")])]),s._v(\" \"),t(\"p\",[t(\"img\",{attrs:{src:\"https://czynotebook.oss-cn-beijing.aliyuncs.com/notebook/put.png\",alt:\" \"}})]),s._v(\" \"),t(\"div\",{staticClass:\"language-java line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"public\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"put\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"putVal\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"hash\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"false\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token boolean\"}},[s._v(\"true\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"putVal\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" hash\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"boolean\")]),s._v(\" onlyIfAbsent\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\"\\n                   \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"boolean\")]),s._v(\" evict\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\" tab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" p\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" n\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" i\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// table未初始化或者长度为0，进行扩容\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"tab \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" table\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"||\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"n \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" tab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"length\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n        n \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"tab \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"resize\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"length\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// (n - 1) & hash 确定元素存放在哪个桶中，桶为空，新生成结点放入桶中(此时，这个结点是放在数组中)\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"p \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" tab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),s._v(\"i \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"n \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"-\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&\")]),s._v(\" hash\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n        tab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),s._v(\"i\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"newNode\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"hash\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 桶中已经存在元素（处理hash冲突）\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"else\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),s._v(\" k\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//快速判断第一个节点table[i]的key是否与插入的key一样，若相同就直接使用插入的值p替换掉旧的值e。\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"p\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"hash \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" hash \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&&\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"k \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" p\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" key \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"||\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"key \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"!=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&&\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"equals\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"k\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n                e \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" p\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 判断插入的是否是红黑树节点\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"else\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"p \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"instanceof\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"TreeNode\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 放入树中\")]),s._v(\"\\n            e \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"TreeNode\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"p\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"putTreeVal\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"this\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" tab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" hash\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 不是红黑树节点则说明为链表结点\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"else\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 在链表最末插入结点\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"for\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" binCount \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"++\")]),s._v(\"binCount\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 到达链表的尾部\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"e \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" p\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"next\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 在尾部插入新结点\")]),s._v(\"\\n                    p\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"next \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"newNode\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"hash\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 结点数量达到阈值(默认为 8 )，执行 treeifyBin 方法\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 这个方法会根据 HashMap 数组来决定是否转换为红黑树。\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 只有当数组长度大于或者等于 64 的情况下，才会执行转换红黑树操作，以减少搜索时间。否则，就是只是对数组扩容。\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"binCount \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\">=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"TREEIFY_THRESHOLD\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"-\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// -1 for 1st\")]),s._v(\"\\n                        \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"treeifyBin\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"tab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" hash\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 跳出循环\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"break\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 判断链表中结点的key值与插入的元素的key值是否相等\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"hash \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" hash \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&&\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"k \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" key \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"||\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"key \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"!=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&&\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"equals\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"k\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 相等，跳出循环\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"break\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 用于遍历桶中的链表，与前面的e = p.next组合，可以遍历链表\")]),s._v(\"\\n                p \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 表示在桶中找到key值、hash值与插入元素相等的结点\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"e \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"!=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 记录e的value\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),s._v(\" oldValue \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// onlyIfAbsent为false或者旧值为null\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"!\")]),s._v(\"onlyIfAbsent \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"||\")]),s._v(\" oldValue \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//用新值替换旧值\")]),s._v(\"\\n                e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"value \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 访问后回调\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"afterNodeAccess\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 返回旧值\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" oldValue\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 结构性修改\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"++\")]),s._v(\"modCount\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 实际大小大于阈值则扩容\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"++\")]),s._v(\"size \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\">\")]),s._v(\" threshold\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"resize\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 插入后回调\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"afterNodeInsertion\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"evict\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"15\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"16\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"17\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"18\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"19\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"20\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"21\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"22\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"23\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"24\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"25\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"26\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"27\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"28\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"29\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"30\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"31\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"32\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"33\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"34\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"35\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"36\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"37\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"38\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"39\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"40\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"41\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"42\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"43\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"44\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"45\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"46\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"47\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"48\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"49\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"50\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"51\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"52\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"53\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"54\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"55\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"56\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"57\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"58\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"59\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"60\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"61\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"62\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"63\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"64\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"65\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"66\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"67\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"68\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"69\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"70\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"71\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"72\")]),t(\"br\")])]),t(\"p\",[t(\"strong\",[s._v(\"我们再来对比一下 JDK1.7 put 方法的代码\")])]),s._v(\" \"),t(\"p\",[t(\"strong\",[s._v(\"对于 put 方法的分析如下：\")])]),s._v(\" \"),t(\"ul\",[t(\"li\",[s._v(\"① 如果定位到的数组位置没有元素 就直接插入。\")]),s._v(\" \"),t(\"li\",[s._v(\"② 如果定位到的数组位置有元素，\"),t(\"strong\",[s._v(\"遍历以这个元素为头结点的链表，依次和插入的 key 比较，如果 key 相同就直接覆盖，不同就采用头插法插入元素。\")])])]),s._v(\" \"),t(\"div\",{staticClass:\"language-java line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"public\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"put\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"table \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"EMPTY_TABLE\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"inflateTable\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"threshold\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"key \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"putForNullKey\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" hash \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"hash\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" i \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"indexFor\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"hash\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" table\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"length\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"for\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Entry\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" e \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" table\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),s._v(\"i\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" e \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"!=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" e \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"next\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 先遍历\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Object\")]),s._v(\" k\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"hash \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" hash \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&&\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"k \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" key \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"||\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"equals\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"k\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),s._v(\" oldValue \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"value \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"recordAccess\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"this\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" oldValue\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\\n    modCount\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"++\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"addEntry\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"hash\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" i\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"  \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 再插入\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"15\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"16\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"17\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"18\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"19\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"20\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"21\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"22\")]),t(\"br\")])]),t(\"h3\",{attrs:{id:\"get-方法\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#get-方法\"}},[s._v(\"#\")]),s._v(\" get 方法\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-java line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"public\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"get\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Object\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"e \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"getNode\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"hash\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"?\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\":\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"getNode\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" hash\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Object\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\" tab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" first\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" n\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),s._v(\" k\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"tab \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" table\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"!=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&&\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"n \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" tab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"length\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\">\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&&\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"first \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" tab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"n \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"-\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&\")]),s._v(\" hash\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"!=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 数组元素相等\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"first\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"hash \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" hash \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&&\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// always check first node\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"k \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" first\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" key \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"||\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"key \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"!=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&&\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"equals\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"k\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" first\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 桶中不止一个节点\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"e \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" first\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"next\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"!=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 在树中get\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"first \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"instanceof\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"TreeNode\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"TreeNode\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"first\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"getTreeNode\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"hash\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 在链表中get\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"do\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"hash \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" hash \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&&\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"k \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" key \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"||\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"key \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"!=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&&\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"equals\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"k\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"while\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"e \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"next\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"!=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"15\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"16\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"17\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"18\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"19\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"20\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"21\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"22\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"23\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"24\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"25\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"26\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"27\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"28\")]),t(\"br\")])]),t(\"h3\",{attrs:{id:\"resize-方法-扩容机制\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#resize-方法-扩容机制\"}},[s._v(\"#\")]),s._v(\" resize 方法  扩容机制\")]),s._v(\" \"),t(\"p\",[s._v(\"进行扩容，会伴随着一次重新 hash 分配，并且会遍历 hash 表中所有的元素，是非常耗时的。\"),t(\"strong\",[s._v(\"在编写程序中，要尽量避免 resize\")]),s._v(\"。resize 方法实际上是将 \"),t(\"strong\",[s._v(\"table 初始化和 table 扩容 进行了整合，底层的行为都是给 table 赋值一个新的数组。\")])]),s._v(\" \"),t(\"div\",{staticClass:\"language-java line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"resize\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\" oldTab \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" table\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" oldCap \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"oldTab \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"?\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\":\")]),s._v(\" oldTab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"length\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" oldThr \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" threshold\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" newCap\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" newThr \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"oldCap \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\">\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 超过最大值就不再扩充了，就只好随你碰撞去吧\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"oldCap \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\">=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"MAXIMUM_CAPACITY\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n            threshold \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Integer\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"MAX_VALUE\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" oldTab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 没超过最大值，就扩充为原来的2倍\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"else\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"newCap \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" oldCap \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"<<\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"<\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"MAXIMUM_CAPACITY\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&&\")]),s._v(\" oldCap \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\">=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"DEFAULT_INITIAL_CAPACITY\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n            newThr \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" oldThr \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"<<\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// double threshold\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"else\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"oldThr \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\">\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// initial capacity was placed in threshold\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 创建对象时初始化容量大小放在threshold中，此时只需要将其作为新的数组容量\")]),s._v(\"\\n        newCap \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" oldThr\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"else\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// signifies using defaults 无参构造函数创建的对象在这里计算容量和阈值\")]),s._v(\"\\n        newCap \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"DEFAULT_INITIAL_CAPACITY\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        newThr \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"DEFAULT_LOAD_FACTOR\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"*\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"DEFAULT_INITIAL_CAPACITY\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"newThr \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 创建时指定了初始化容量或者负载因子，在这里进行阈值初始化，\")]),s._v(\"\\n    \\t\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 或者扩容前的旧容量小于16，在这里计算新的resize上限\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"float\")]),s._v(\" ft \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"float\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"newCap \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"*\")]),s._v(\" loadFactor\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        newThr \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"newCap \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"<\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"MAXIMUM_CAPACITY\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&&\")]),s._v(\" ft \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"<\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"float\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"MAXIMUM_CAPACITY\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"?\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"ft \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\":\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Integer\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"MAX_VALUE\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    threshold \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" newThr\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token annotation punctuation\"}},[s._v(\"@SuppressWarnings\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"rawtypes\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"unchecked\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\" newTab \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"new\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),s._v(\"newCap\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    table \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" newTab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"oldTab \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"!=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 把每个bucket都移动到新的buckets中\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"for\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" j \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" j \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"<\")]),s._v(\" oldCap\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"++\")]),s._v(\"j\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"e \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" oldTab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),s._v(\"j\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"!=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n                oldTab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),s._v(\"j\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"next \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 只有一个节点，直接计算元素新的位置即可\")]),s._v(\"\\n                    newTab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),s._v(\"e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"hash \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"newCap \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"-\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"else\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"e \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"instanceof\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"TreeNode\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 将红黑树拆分成2棵子树，如果子树节点数小于等于 UNTREEIFY_THRESHOLD（默认为 6），则将子树转换为链表。\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 如果子树节点数大于 UNTREEIFY_THRESHOLD，则保持子树的树结构。\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"TreeNode\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"split\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"this\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" newTab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" j\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" oldCap\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"else\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" loHead \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" loTail \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" hiHead \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" hiTail \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" next\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"do\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n                        next \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"next\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 原索引\")]),s._v(\"\\n                        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"hash \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&\")]),s._v(\" oldCap\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n                            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"loTail \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n                                loHead \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"else\")]),s._v(\"\\n                                loTail\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"next \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                            loTail \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n                        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 原索引+oldCap\")]),s._v(\"\\n                        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"else\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n                            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"hiTail \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n                                hiHead \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"else\")]),s._v(\"\\n                                hiTail\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"next \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                            hiTail \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"while\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"e \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" next\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"!=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 原索引放到bucket里\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"loTail \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"!=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n                        loTail\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"next \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                        newTab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),s._v(\"j\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" loHead\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 原索引+oldCap放到bucket里\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"hiTail \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"!=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n                        hiTail\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"next \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                        newTab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),s._v(\"j \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"+\")]),s._v(\" oldCap\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" hiHead\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" newTab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"15\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"16\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"17\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"18\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"19\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"20\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"21\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"22\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"23\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"24\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"25\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"26\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"27\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"28\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"29\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"30\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"31\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"32\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"33\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"34\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"35\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"36\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"37\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"38\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"39\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"40\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"41\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"42\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"43\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"44\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"45\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"46\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"47\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"48\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"49\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"50\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"51\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"52\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"53\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"54\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"55\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"56\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"57\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"58\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"59\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"60\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"61\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"62\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"63\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"64\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"65\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"66\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"67\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"68\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"69\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"70\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"71\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"72\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"73\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"74\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"75\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"76\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"77\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"78\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"79\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"80\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"81\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"82\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"83\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"84\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"85\")]),t(\"br\")])]),t(\"h2\",{attrs:{id:\"hashmap-常用方法测试\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#hashmap-常用方法测试\"}},[s._v(\"#\")]),s._v(\" HashMap 常用方法测试\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-java line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"package\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token namespace\"}},[s._v(\"map\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token import\"}},[t(\"span\",{pre:!0,attrs:{class:\"token namespace\"}},[s._v(\"java\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"util\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")])]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Collection\")])]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token import\"}},[t(\"span\",{pre:!0,attrs:{class:\"token namespace\"}},[s._v(\"java\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"util\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")])]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"HashMap\")])]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token import\"}},[t(\"span\",{pre:!0,attrs:{class:\"token namespace\"}},[s._v(\"java\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"util\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")])]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Set\")])]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"public\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"class\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"HashMapDemo\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"public\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"static\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"void\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"main\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"String\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\" args\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"HashMap\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"String\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"String\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" map \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"new\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"HashMap\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"String\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"String\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 键不能重复，值可以重复\")]),s._v(\"\\n        map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"put\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"san\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"张三\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"put\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"si\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"李四\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"put\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"wu\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"王五\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"put\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"wang\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"老王\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"put\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"wang\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"老王2\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 老王被覆盖\")]),s._v(\"\\n        map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"put\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"lao\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"老王\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"System\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"out\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"println\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"-------直接输出hashmap:-------\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"System\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"out\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"println\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"/**\\n         * 遍历HashMap\\n         */\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 1.获取Map中的所有键\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"System\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"out\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"println\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"-------foreach获取Map中所有的键:------\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Set\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"String\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" keys \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"keySet\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"for\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"String\")]),s._v(\" key \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\":\")]),s._v(\" keys\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"System\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"out\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"key\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"+\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"  \"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"System\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"out\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"println\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//换行\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 2.获取Map中所有值\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"System\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"out\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"println\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"-------foreach获取Map中所有的值:------\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Collection\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"String\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" values \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"values\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"for\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"String\")]),s._v(\" value \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\":\")]),s._v(\" values\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"System\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"out\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"value\"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"+\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"  \"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"System\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"out\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"println\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//换行\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 3.得到key的值的同时得到key所对应的值\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"System\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"out\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"println\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"-------得到key的值的同时得到key所对应的值:-------\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Set\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"String\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" keys2 \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"keySet\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"for\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"String\")]),s._v(\" key \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\":\")]),s._v(\" keys2\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"System\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"out\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"print\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"key \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"+\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"：\"')]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"+\")]),s._v(\" map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"get\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"+\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"   \"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"/**\\n         * 如果既要遍历key又要value，那么建议这种方式，因为如果先获取keySet然后再执行map.get(key)，map内部会执行两次遍历。\\n         * 一次是在获取keySet的时候，一次是在遍历所有key的时候。\\n         */\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 当我调用put(key,value)方法的时候，首先会把key和value封装到\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// Entry这个静态内部类对象中，把Entry对象再添加到数组中，所以我们想获取\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// map中的所有键值对，我们只要获取数组中的所有Entry对象，接下来\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 调用Entry对象中的getKey()和getValue()方法就能获取键值对了\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Set\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t(\"span\",{pre:!0,attrs:{class:\"token namespace\"}},[s._v(\"java\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"util\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")])]),s._v(\"Map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"Entry\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"String\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"String\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" entrys \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"entrySet\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"for\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t(\"span\",{pre:!0,attrs:{class:\"token namespace\"}},[s._v(\"java\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"util\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")])]),s._v(\"Map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"Entry\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"String\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"String\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" entry \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\":\")]),s._v(\" entrys\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"System\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"out\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"println\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"entry\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"getKey\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"+\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"--\"')]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"+\")]),s._v(\" entry\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"getValue\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"/**\\n         * HashMap其他常用方法\\n         */\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"System\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"out\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"println\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"after map.size()：\"')]),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"+\")]),s._v(\"map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"size\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"System\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"out\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"println\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"after map.isEmpty()：\"')]),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"+\")]),s._v(\"map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"isEmpty\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"System\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"out\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"println\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"remove\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"san\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"System\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"out\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"println\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"after map.remove()：\"')]),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"+\")]),s._v(\"map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"System\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"out\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"println\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"after map.get(si)：\"')]),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"+\")]),s._v(\"map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"get\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"si\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"System\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"out\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"println\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"after map.containsKey(si)：\"')]),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"+\")]),s._v(\"map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"containsKey\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"si\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"System\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"out\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"println\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"after containsValue(李四)：\"')]),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"+\")]),s._v(\"map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"containsValue\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"李四\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"System\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"out\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"println\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"replace\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"si\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"李四2\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"System\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"out\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"println\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"after map.replace(si, 李四2):\"')]),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"+\")]),s._v(\"map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"15\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"16\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"17\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"18\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"19\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"20\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"21\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"22\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"23\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"24\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"25\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"26\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"27\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"28\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"29\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"30\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"31\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"32\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"33\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"34\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"35\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"36\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"37\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"38\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"39\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"40\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"41\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"42\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"43\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"44\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"45\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"46\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"47\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"48\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"49\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"50\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"51\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"52\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"53\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"54\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"55\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"56\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"57\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"58\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"59\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"60\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"61\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"62\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"63\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"64\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"65\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"66\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"67\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"68\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"69\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"70\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"71\")]),t(\"br\")])])])}),[],!1,null,null,null);t.default=e.exports}}]);","extractedComments":[]}